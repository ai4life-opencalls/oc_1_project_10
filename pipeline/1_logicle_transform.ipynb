{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import flowkit as fk\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import ask_directory\n",
    "from data import get_df\n",
    "from logicle_scaling import logicle_transform\n",
    "\n",
    "\n",
    "SEED = 7\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the raw data directory (*FCS* files):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mehdi.seifi/Projects/AI4Life/project_10_sorting/data\n"
     ]
    }
   ],
   "source": [
    "raw_data_dir = ask_directory(title=\"Select your data directory\")\n",
    "\n",
    "print(raw_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data_dir = Path(raw_data_dir)\n",
    "fcs_files = raw_data_dir.glob(\"**/*.fcs\")\n",
    "sample_files = []\n",
    "for fcs in fcs_files:\n",
    "    has_images = len(list(fcs.parent.glob(\"*images\"))) > 0\n",
    "    sample_files.append((fcs, has_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select samples to transform into the Logicle scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fdb64f4af4416d8d70857178c5c718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select Samples:', index=(1, 2, 3, 4, 5, 9), options=('Amphidinium.fcs (images: Falâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selector = widgets.SelectMultiple(\n",
    "    options=[f\"{item[0].name} (images: {item[1]})\" for item in sample_files],\n",
    "    value=[f\"{item[0].name} (images: {item[1]})\" for item in sample_files if item[1]],\n",
    "    rows=14,\n",
    "    description=\"Select Samples:\"\n",
    ")\n",
    "\n",
    "display(selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the folder where you want to save transformed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_data_dir = ask_directory(\"Where to save transformed data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mehdi.seifi/Projects/AI4Life/project_10_sorting/data/transformed_data\n"
     ]
    }
   ],
   "source": [
    "transformed_data_dir = Path(transformed_data_dir)\n",
    "transformed_data_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(transformed_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save configs\n",
    "with open(\"./config.json\", mode=\"w\") as f:\n",
    "    json.dump({\n",
    "        \"raw_data_dir\": str(raw_data_dir.absolute()),\n",
    "        \"logicle_data_dir\": str(transformed_data_dir.absolute())\n",
    "    }, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data and dropping uninformative channels (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_samples = [sample_files[i] for i in selector.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d999d3bc288f4ef683c4df5b9ecfd83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing/cleaning samples:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proessing Skeletonema\n",
      "proessing Lingodinium\n",
      "proessing C.6818\n",
      "proessing Emiliana_huxley\n",
      "proessing Phaeodactylum\n",
      "proessing Synechococcus\n"
     ]
    }
   ],
   "source": [
    "# process samples dataframes and drop uninformative columns\n",
    "dataframes = {}\n",
    "all_drop_cols = [\"Saturated\", \"Time\"]\n",
    "\n",
    "for path, _ in tqdm(selected_samples, desc=\"processing/cleaning samples\"):\n",
    "    name = path.stem\n",
    "    print(f\"proessing {name}\")\n",
    "    df, drop_cols = get_df(path)\n",
    "    dataframes[name] = df\n",
    "    all_drop_cols.extend(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_drop_cols = set(all_drop_cols)\n",
    "dataframes = {\n",
    "    name: df.drop(columns=all_drop_cols, errors=\"ignore\")\n",
    "    for name, df in dataframes.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform selected data into the Logicle scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1bb1b8b6b04d9083d7f5f0e76d5d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dataframes:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9f0a276aa94a6ab84d683477339d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skeletonema: applying logicle transform on channels:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f704f6f8424eacbdb94816208373df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lingodinium: applying logicle transform on channels:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0e5eda31c44b5b91cb49a6e2f90c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C.6818: applying logicle transform on channels:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2444e12690c468ab2fcb485a966a7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Emiliana_huxley: applying logicle transform on channels:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e84c07998f4a4797870d520677e07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Phaeodactylum: applying logicle transform on channels:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7d19658b774e0a9915478367ad6a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Synechococcus: applying logicle transform on channels:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logicle_dataframes = {}\n",
    "logicle_cols = [\n",
    "    \"top_of_scale\", \"m_positive_decades\",\n",
    "    \"width_of_linear\", \"addition_negative\"\n",
    "]\n",
    "\n",
    "for name in tqdm(dataframes.keys(), desc=\"Dataframes\", position=0):\n",
    "    # hdf5 storage\n",
    "    storage = pd.HDFStore(transformed_data_dir.joinpath(f\"./{name}.h5\"), mode=\"w\")\n",
    "\n",
    "    logicle_transforms = {}\n",
    "    df = dataframes[name].copy()\n",
    "    for col in tqdm(df.columns, desc=f\"{name}: applying logicle transform on channels\", position=1, leave=True):\n",
    "        df[col], logicle = logicle_transform(df[col].to_numpy(), return_transform=True)\n",
    "        logicle_transforms[col] = logicle.get_params()\n",
    "    \n",
    "    storage[\"df\"] = df\n",
    "    storage[\"logicles\"] = pd.DataFrame(\n",
    "        data=list(logicle_transforms.values()),\n",
    "        index=list(logicle_transforms.keys()),\n",
    "        columns=logicle_cols\n",
    "    )\n",
    "\n",
    "    storage.close()\n",
    "\n",
    "    logicle_dataframes[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
