{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import flowkit as fk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import ask_directory\n",
    "from pair_precision import (\n",
    "    get_logicle_polygon_gates,\n",
    "    get_pair_precisions\n",
    ")\n",
    "\n",
    "\n",
    "SEED = 7\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create \"results\" folder to keep gate pairs scores and ...\n",
    "Path(\"./results\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions to separate alive vs. others\n",
    "\n",
    "TIFF_NAME_FORMAT = \"{name}_{id:08d}.tiff\"\n",
    "\n",
    "def get_id_from_tiff_path(tiff_path: Path):\n",
    "    return int(tiff_path.stem.split(\"_\")[-1])\n",
    "\n",
    "\n",
    "def get_tiff_filtered_dataframes(dataframes: dict, sample_paths: dict):\n",
    "    results = {}\n",
    "    for sample_name, hdf_path in tqdm(dataframes.items(), desc=\"separating samples with tiff\"):\n",
    "        df = pd.read_hdf(hdf_path, key=\"df\")\n",
    "        image_path = sample_paths[sample_name].parent.joinpath(\"images\")\n",
    "        all_tiffs = list(image_path.glob(\"**/*.tiff\"))\n",
    "        rows_with_tiff = [get_id_from_tiff_path(img_path) for img_path in all_tiffs]\n",
    "        df_with_tiff = df.iloc[rows_with_tiff]\n",
    "        df_without_tiff = df.drop(index=rows_with_tiff)\n",
    "        df_logicles = pd.read_hdf(hdf_path, key=\"logicles\")\n",
    "        print(\n",
    "            f\"{sample_name:<20}: Total: {len(df):<7,d} | With tiff: {len(df_with_tiff):<7,d} | \"\n",
    "            f\"Without tiff: {len(df_without_tiff):,d}.\"\n",
    "        )\n",
    "        results[sample_name] = [df_without_tiff, df_with_tiff, df_logicles]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load config from the previous step, if it's available\n",
    "config = {}\n",
    "config_file = Path(\"./config.json\")\n",
    "if config_file.exists():\n",
    "    with open(config_file, mode=\"r\") as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the raw data directory (*FCS* files):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data_dir = config.get(\"raw_data_dir\", None)\n",
    "\n",
    "if raw_data_dir is None:\n",
    "    raw_data_dir = ask_directory(\"Select your data directory\")\n",
    "\n",
    "raw_data_dir = Path(raw_data_dir)\n",
    "print(raw_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fcs_files = raw_data_dir.glob(\"**/*.fcs\")\n",
    "sample_paths = {}\n",
    "for fcs in fcs_files:\n",
    "    has_images = len(list(fcs.parent.glob(\"*images\"))) > 0\n",
    "    if has_images:\n",
    "        sample_paths[fcs.stem] = fcs\n",
    "\n",
    "print(\"Sample files with images:\")\n",
    "pprint(sample_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the Logicle transformed directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_data_dir = config.get(\"logicle_data_dir\", None)\n",
    "if transformed_data_dir is None:\n",
    "    transformed_data_dir = ask_directory(\"Select directory of the transformed data\")\n",
    "\n",
    "transformed_data_dir = Path(transformed_data_dir)\n",
    "print(transformed_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logicle_samples = {}\n",
    "h5_files = transformed_data_dir.glob(\"*.h5\")\n",
    "for file in h5_files:\n",
    "    logicle_samples[file.stem] = file\n",
    "\n",
    "print(\"Logicle transformed data files:\")\n",
    "pprint(logicle_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating alive samples vs. others for each species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "species_dfs = get_tiff_filtered_dataframes(logicle_samples, sample_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the target species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selector = widgets.Select(\n",
    "    options=[sp_name for sp_name in species_dfs],\n",
    "    rows=14,\n",
    "    description=\"Target species:\"\n",
    ")\n",
    "\n",
    "display(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_species = selector.value\n",
    "print(f\"Your target species: {target_species}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the target alive samples\n",
    "df_alive = species_dfs[target_species][1]\n",
    "\n",
    "# get others species samples\n",
    "df_others = []\n",
    "for name in species_dfs:\n",
    "    if name != target_species:\n",
    "        df_others.append(species_dfs[name][0])\n",
    "        df_others.append(species_dfs[name][1])\n",
    "\n",
    "df_others = pd.concat(df_others)\n",
    "\n",
    "\n",
    "print(f\"alive: {df_alive.shape}, others: {df_others.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to free some memory up\n",
    "del species_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(np.vstack((\n",
    "    df_alive.to_numpy(),\n",
    "    df_others.to_numpy()\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alive_normed = scaler.transform(df_alive.to_numpy())\n",
    "others_normed = scaler.transform(df_others.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Fisher Discriminant Ratio (FDR) for each channel:\n",
    "(For two classes alive vs. others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alive_mu = alive_normed.mean(axis=0)\n",
    "others_mu = others_normed.mean(axis=0)\n",
    "\n",
    "alive_vars = alive_normed.var()\n",
    "others_vars = others_normed.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fishers = np.power(alive_mu - others_mu, 2) / (alive_vars + others_vars)\n",
    "fishers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_fisher = pd.DataFrame(data={\n",
    "    \"channel\": df_alive.columns, \"fisher\": fishers\n",
    "}).sort_values(\"fisher\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_fisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get fisher score for each possible pair (average of two channels in a pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pairs_cols = np.array(\n",
    "    list(itertools.combinations(df_alive.columns.to_list(), 2))\n",
    ")\n",
    "\n",
    "pprint(all_pairs_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pair_fishers = np.zeros(len(all_pairs_cols))\n",
    "\n",
    "for i, pair in tqdm(\n",
    "    enumerate(all_pairs_cols), total=len(all_pairs_cols), desc=\"Getting pairs' fishers\"\n",
    "):\n",
    "    # print(pair)\n",
    "    fisher_col1 = df_fisher[df_fisher[\"channel\"] == pair[0]][\"fisher\"].to_numpy()[0]\n",
    "    fisher_col2 = df_fisher[df_fisher[\"channel\"] == pair[1]][\"fisher\"].to_numpy()[0]\n",
    "    pair_fishers[i] = (fisher_col1 + fisher_col2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pair_fishers = pd.DataFrame(data={\n",
    "    \"channel_1\": all_pairs_cols[:, 0],\n",
    "    \"channel_2\": all_pairs_cols[:, 1],\n",
    "    \"fisher_avg\": pair_fishers\n",
    "})\n",
    "\n",
    "df_pair_fishers = df_pair_fishers.round(4).sort_values(\n",
    "    \"fisher_avg\", ascending=False).reset_index(drop=True)\n",
    "df_pair_fishers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Pairs: \n",
    "\n",
    "#### 1. Select pairs with fisher score above the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fisher_mean = df_pair_fishers[\"fisher_avg\"].mean().round(4)\n",
    "print(fisher_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = df_pair_fishers[\"fisher_avg\"] > fisher_mean\n",
    "df_pair_fisher_above_mean = df_pair_fishers[mask].reset_index(drop=True)\n",
    "\n",
    "df_pair_fisher_above_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. For each channel selected by the previous step, select pairs with having fisher score above the 50% (median):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_top_pairs(channel_list, df_fisher):\n",
    "    best_matches = []\n",
    "    for channel in tqdm(channel_list, desc=\"Proposing best matches\"):\n",
    "        ch_mask = df_fisher[\"channel_1\"] == channel\n",
    "        if ch_mask.sum() > 0:\n",
    "            channel_pairs = df_fisher[ch_mask].sort_values(\"fisher_avg\", ascending=False)\n",
    "            ch_threshold = np.quantile(channel_pairs[\"fisher_avg\"], 0.5)\n",
    "            top_matches = channel_pairs[channel_pairs[\"fisher_avg\"] >= ch_threshold]\n",
    "            best_matches.append(top_matches)\n",
    "\n",
    "    return pd.concat(best_matches).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_top_pairs = get_top_pairs(df_alive.columns.to_list(), df_pair_fisher_above_mean)\n",
    "df_top_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the top pairs\n",
    "df_top_pairs.to_csv(f\"./results/{target_species}_top_pairs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the average vector of the alive samples (with images) for the target species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the target species data in logicle space\n",
    "df_positive_logicle = pd.read_hdf(logicle_samples[target_species], key=\"df\")\n",
    "df_positive_logicle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get channel's logicle params\n",
    "df_logicle_params = pd.read_hdf(logicle_samples[target_species], key=\"logicles\")\n",
    "df_logicle_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alive (with tiffs) samples average vector\n",
    "target_alive_vector = df_alive.mean().to_numpy()\n",
    "# np.save(f\"./results/{target_species}_alive_vector.npy\", target_alive_vector)\n",
    "target_alive_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the similarity between all samples with the alive average vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the cosine similarity between alive average vector and each row of data\n",
    "data = df_positive_logicle.to_numpy()\n",
    "sim_mat = np.dot(data, target_alive_vector)\n",
    "sim_mat /= (\n",
    "    np.linalg.norm(data, axis=1) *\n",
    "    np.linalg.norm(target_alive_vector)\n",
    ")\n",
    "# print(sim_mat.min(), sim_mat.max(), sim_mat.mean())\n",
    "\n",
    "# add weights to make a better distribution of the similarities\n",
    "weights = (sim_mat - np.mean(sim_mat))\n",
    "sim_mat = weights * sim_mat\n",
    "\n",
    "# scale similarity to the range of [0, 1]\n",
    "sim_mat = (sim_mat - sim_mat.min()) / (sim_mat.max() - sim_mat.min())\n",
    "# print(sim_mat.min(), sim_mat.max(), sim_mat.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the threshold of the similarity:\n",
    "##### Higher threshold will produce tighter gate with more pure samples but less in numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# threshold the similarity\n",
    "threshold_slider = widgets.FloatSlider(\n",
    "    value=0.85,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    description=\"Similarity Threshold:\",\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation=\"horizontal\",\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    ")\n",
    "display(threshold_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "similarity_threshold = threshold_slider.value\n",
    "print(similarity_threshold)\n",
    "\n",
    "high_sim_mask = sim_mat > similarity_threshold\n",
    "np.save(f\"./results/{target_species}_high_sim_mask.npy\", high_sim_mask)\n",
    "print(f\"Alive-Similar data rows: {high_sim_mask.sum():,d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the threshold effect on a sample pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 6.5))\n",
    "\n",
    "ch1 = df_top_pairs.loc[0, \"channel_1\"]\n",
    "ch2 = df_top_pairs.loc[0, \"channel_2\"]\n",
    "\n",
    "ax.scatter(\n",
    "    df_others[ch2].to_numpy(), df_others[ch1].to_numpy(),\n",
    "    color=\"salmon\", s=7, alpha=0.5\n",
    ")\n",
    "ax.scatter(\n",
    "    df_positive_logicle[ch2].to_numpy()[high_sim_mask], df_positive_logicle[ch1].to_numpy()[high_sim_mask],\n",
    "    color=\"limegreen\", s=9, alpha=0.5\n",
    ")\n",
    "\n",
    "ax.set_xlabel(ch2)\n",
    "ax.set_ylabel(ch1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the polygon gates for the selected top pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logicle_polygon_gates = get_logicle_polygon_gates(df_top_pairs, df_positive_logicle, high_sim_mask)\n",
    "\n",
    "len(logicle_polygon_gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving gates\n",
    "pairs = [\n",
    "    f\"{channels[0]}|{channels[1]}\" for channels in\n",
    "    df_top_pairs[[\"channel_1\", \"channel_2\"]].itertuples(index=False, name=None)\n",
    "]\n",
    "\n",
    "# with open(f\"./results/{target_species}_top_gates.bin\", mode=\"wb\") as f:\n",
    "#     pickle.dump({\n",
    "#         pair:gate for pair, gate in zip(pairs, logicle_polygon_gates)\n",
    "#     }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to free up some memory\n",
    "\n",
    "del df_others\n",
    "del df_positive_logicle\n",
    "del weights\n",
    "del sim_mat\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the precision for each pair/gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load raw data to make positive and negative dataframes\n",
    "df_positive = fk.Sample(sample_paths[target_species]).as_dataframe(source=\"raw\")\n",
    "\n",
    "df_negative = []\n",
    "for sample_name in logicle_samples:\n",
    "    fcs_file = sample_paths[sample_name]\n",
    "    if sample_name != target_species:\n",
    "        df_negative.append(\n",
    "            fk.Sample(fcs_file).as_dataframe(source=\"raw\")\n",
    "        )\n",
    "df_negative = pd.concat(df_negative)\n",
    "\n",
    "# !important: drop second level columns (pns)\n",
    "df_positive = df_positive.droplevel(level=1, axis=1)\n",
    "df_negative = df_negative.droplevel(level=1, axis=1)\n",
    "\n",
    "print(df_positive.shape, df_negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (Takes time!)\n",
    "df_precisions = get_pair_precisions(\n",
    "    df_top_pairs, logicle_polygon_gates, df_logicle_params,\n",
    "    df_positive, df_negative\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_precisions = df_precisions.sort_values(\"precision\", ascending=False).reset_index(drop=True)\n",
    "df_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_precisions.to_csv(f\"./results/{target_species}_gate_precisions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7.5, 6.5))\n",
    "ax.scatter(\n",
    "    df_precisions[\"precision\"], df_precisions[\"fisher_avg\"],\n",
    "    color=\"dodgerblue\", s=11, lw=0\n",
    ")\n",
    "ax.set_title(target_species)\n",
    "ax.set_xlabel(\"Precision\")\n",
    "ax.set_ylabel(\"Fisher Ratio\")\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
